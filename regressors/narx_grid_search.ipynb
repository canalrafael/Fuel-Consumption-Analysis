{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from regressor_utils import *\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from fireTS.models import NARX\n",
    "\n",
    "with open(\"data/feature_selections/xgb_reg_stage2.json\") as f:\n",
    "    features = json.loads(f.read())\n",
    "\n",
    "sfm = features[\"SFM\"]\n",
    "\n",
    "\n",
    "def plot_results(mdl1, ytest, ypred):\n",
    "    fig, axs = plt.subplots(1,3)\n",
    "    fig.set_size_inches(16,6)\n",
    "\n",
    "    axs[0].plot(ytest,label=\"Measured\")\n",
    "    axs[0].plot(ypred,label=\"Predicted\")\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title(\"Measure and prediction vs. time\")\n",
    "\n",
    "    axs[1].plot(ytest - ypred, label=\"Error\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title(\"Error ($y - \\hat y$)\")\n",
    "\n",
    "    axs[2].scatter(ytest,ypred)\n",
    "    axs[2].plot(ytest,ytest)\n",
    "    axs[2].set_title(\"Measure vs. Prediction\")\n",
    "    plt.show()\n",
    "\n",
    "    r2 = metrics.r2_score(np.nan_to_num(ypred),ytest)\n",
    "    mse = metrics.mean_squared_error(np.nan_to_num(ypred),ytest)\n",
    "    maxerr = abs(np.max(ytest-ypred))\n",
    "\n",
    "    print(\"R2 score: \",r2)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"Max error\",maxerr)\n",
    "\n",
    "    return (r2,mse,maxerr)\n",
    "\n",
    "def get_scores(ytest, ypred):\n",
    "    r2 = metrics.r2_score(np.nan_to_num(ypred),ytest)\n",
    "    mse = metrics.mean_squared_error(np.nan_to_num(ypred),ytest)\n",
    "    maxerr = abs(np.max(ytest-ypred))\n",
    "\n",
    "    print(\"R2 score: \",r2)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"Max error\",maxerr)\n",
    "\n",
    "    return (r2,mse,maxerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_paths = [\n",
    "    # STAGE 1\n",
    "    \"data/testes/teste_04_10.parquet\",\n",
    "    \"data/testes/teste_18_10.parquet\"\n",
    "]\n",
    "\n",
    "stage2_paths = [\n",
    "    # STAGE 2\n",
    "    \"data/testes/teste_02_01_13h56min_14h14min.parquet\",\n",
    "    \"data/testes/teste_02_01_17h33min_18h13min.parquet\"\n",
    "]\n",
    "\n",
    "stage3_paths = [\n",
    "    # STAGE 3\n",
    "    \"data/testes/teste_09_02.parquet\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino\n",
    "df = pd.read_parquet(stage2_paths[0])\n",
    "df2 = pd.read_parquet(stage2_paths[1])[:500]\n",
    "\n",
    "\n",
    "x = df[sfm]\n",
    "x2 = df2[sfm]\n",
    "\n",
    "y = df[\"Consumption\"]\n",
    "y2 = df2[\"Consumption\"]\n",
    "\n",
    "delays = [2,3,4,5,6,7]\n",
    "neurons = np.arange(30,110,5)\n",
    "\n",
    "results = []\n",
    "\n",
    "for delay in delays:\n",
    "    for neuron in neurons:\n",
    "        mdl1 = NARX(\n",
    "            MLPRegressor(hidden_layer_sizes=(neuron),solver=\"adam\",max_iter=2000),\n",
    "            auto_order=delay,\n",
    "            exog_order=x.shape[1]*[delay])\n",
    "        mdl1.fit(x, y)\n",
    "\n",
    "        xtest = x\n",
    "        ytest = y.values\n",
    "        yfrcast = mdl1.forecast(xtest[:delay],ytest[:delay],step = ytest.shape[0]-delay, X_future=xtest[delay:ytest.shape[0]-1])\n",
    "        trainscores = get_scores(ytest[delay:],yfrcast)\n",
    "\n",
    "        print(\"\\n\\nTest scores for features \", features)\n",
    "        xtest = x2\n",
    "        ytest = y2.values\n",
    "        yfrcast = mdl1.forecast(xtest[:delay],ytest[:delay],step = ytest.shape[0]-delay, X_future=xtest[delay:ytest.shape[0]-1])\n",
    "        testscores = get_scores( ytest[delay:],yfrcast)\n",
    "\n",
    "        results.append((\n",
    "            f\"Delay = {delay}, N. Neurons = {neuron}\",\n",
    "            trainscores[0],\n",
    "            trainscores[1],\n",
    "            trainscores[2],\n",
    "            testscores[0],\n",
    "            testscores[1],\n",
    "            testscores[2],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-654844151f87>:3: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  resultsdf.to_excel(\"narx_grid_search.xls\")\n"
     ]
    }
   ],
   "source": [
    "resultsdf = pd.DataFrame(results,columns=(\"Settings\",\"train r2\",\"train MSE\",\"train max err\",\"test r2\",\"test MSE\",\"test max err\"))\n",
    "\n",
    "resultsdf.to_excel(\"data/narx_grid_search.xls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
